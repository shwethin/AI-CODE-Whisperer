# ğŸ“ Intelligent Study Timetable & Planner Agent

An AI-powered study planning application that helps you organize your schedule and uses Ollama for personalized study plans.

## âœ¨ Features

- ğŸ¤– **AI Study Plans** - Powered by Ollama (llama3)
- ğŸ“… **Visual Calendar** - Monthly and yearly views with event tracking
- ğŸ¯ **Smart Prioritization** - Automatic priority calculation based on deadlines
- ğŸ’¾ **Local Profile** - Personalize your experience with a simple Name/Age profile
- ğŸ¨ **Premium UI** - Glassmorphism dark mode design
- ğŸš€ **Zero External Dependencies** - Pure Python server (standard library only)

## ğŸ“ Project Structure

```
ai/
â”œâ”€â”€ server.py                    # Main Python server (port 8081)
â”œâ”€â”€ requirements.txt             # Python dependencies (optional for AI)
â”œâ”€â”€ static/                      # Frontend files
â”‚   â”œâ”€â”€ index.html              # Main UI
â”‚   â”œâ”€â”€ script.js               # Frontend logic
â”‚   â””â”€â”€ style.css               # Styling
â”œâ”€â”€ core/                        # Core modules
â”‚   â”œâ”€â”€ agent.py                # Planning engine
â”‚   â””â”€â”€ models.py               # Data models
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ Dockerfile                  # Docker configuration
â”œâ”€â”€ app.yaml                    # App Engine config
â”œâ”€â”€ cloudbuild.yaml             # Cloud Build config
â””â”€â”€ docs/                       # Documentation
    â”œâ”€â”€ OLLAMA_GUIDE.md
    â”œâ”€â”€ OLLAMA_TROUBLESHOOTING.md
    â””â”€â”€ DEPLOYMENT_GUIDE.md
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.7+
- Ollama (optional, for AI features)

### Run Locally

```bash
# 1. Navigate to project folder
cd c:\Users\albin\Desktop\ai

# 2. Start the server
python server.py

# 3. Open in browser
http://localhost:8081
```

### With Ollama AI (Optional)

```bash
# 1. Install Ollama
# Download from: https://ollama.com

# 2. Start Ollama server
ollama serve

# 3. Pull model
ollama pull llama3

# 4. Start your app
python server.py
```

## ğŸ“– Usage

### First Time Setup
1. Visit `http://localhost:8081`
2. Enter your **Name** and **Age** in the welcome screen.
3. Click "Start Planning ğŸš€".

### Main Features
1. **Add Subjects**: Go to "Subjects" tab and add your courses (e.g., Math, History).
2. **Add Assignments**: Go to "Assignments" tab and add tasks with deadlines.
3. **Calendar**: View your schedule in Month or Year view.
4. **AI Plan**: Click "Generate Plan âš¡" to get a daily schedule for your tasks.

## ğŸ”§ Configuration

### Change Port
Edit `server.py` line 9:
```python
PORT = 8081  # Change to your preferred port
```

### Change AI Model
Edit `server.py` line 95:
```python
"model": "llama3",  # Try: mistral, gemma, etc.
```

## ğŸŒ Deployment

### Google Cloud Run
```bash
gcloud run deploy study-agent --source . --region us-central1
```

### Docker
```bash
docker build -t study-agent .
docker run -p 8081:8081 study-agent
```

See `DEPLOYMENT_GUIDE.md` for complete instructions.

## ğŸ“š Documentation

- **OLLAMA_GUIDE.md** - Ollama integration guide
- **OLLAMA_TROUBLESHOOTING.md** - Fix Ollama issues
- **DEPLOYMENT_GUIDE.md** - Deploy to cloud

## ğŸ› Troubleshooting

### 404 Error
- Make sure server is running on port 8081
- Check terminal for errors
- Restart: `Ctrl+C` then `python server.py`

### Ollama Not Working
- Start Ollama: `ollama serve`
- Pull model: `ollama pull llama3`
- See: `OLLAMA_TROUBLESHOOTING.md`

## ğŸ“Š Tech Stack

- **Backend**: Python (http.server, urllib)
- **Frontend**: HTML5, CSS3, Vanilla JavaScript
- **AI**: Ollama (llama3)
- **Styling**: Custom CSS (Glassmorphism)

## ğŸ“„ License

This project is for educational purposes.

## ğŸ¤ Contributing

This is a personal study tool. Feel free to fork and customize!

---

**Made with â¤ï¸ for students**

**Current Version**: 1.1.0  
**Server Port**: 8081  
**Status**: âœ… Running
